{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f52882-ee01-4463-9b26-91a8869edd84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c525dd3b-efc2-4e8f-97fd-2f42f114a4de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "expense = pd.read_csv('Detailed_Expense_Breakdown.csv')\n",
    "revenue = pd.read_csv('Detailed_Revenue_Breakdown.csv')\n",
    "debt = pd.read_csv('Historical Public Debt Database.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2055a26-f476-4065-8afa-1ddce1dfbdc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fix column titles\n",
    "\n",
    "expense.columns = expense.columns.str.lower().str.replace(' ', '_')\n",
    "revenue.columns = revenue.columns.str.lower().str.replace(' ', '_')\n",
    "debt.columns = debt.columns.str.lower().str.replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bccaf15-cb04-4637-895b-c97ce62b73ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "european_countries = [\n",
    "    'Portugal', 'Romania', 'Russia', 'San Marino', 'São Tomé and Príncipe', 'Serbia',\n",
    "    'Seychelles', 'Slovak Republic', 'Slovenia', 'Spain', 'Sweden', 'Italy',\n",
    "    'Switzerland', 'Poland', 'Norway', 'Netherlands', 'Montenegro, Rep. of', 'Luxembourg',\n",
    "    'Lithuania', 'Latvia', 'Kosovo', 'Iceland', 'Hungary', 'Greece', 'Germany',\n",
    "    'France', 'Finland', 'Estonia', 'Euro area', 'Belgium', 'Austria', 'Albania',\n",
    "    'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Cyprus', 'Czech Republic', 'Denmark',\n",
    "    'United Kingdom', 'Turkey', 'Ukraine', 'Switzerland', 'Sweden', 'Spain', 'Slovenia'\n",
    "   \n",
    "]\n",
    "\n",
    "# Filter the \"expense\" DataFrame for European countries\n",
    "expense_europe = expense[expense['country_name'].isin(european_countries)]\n",
    "\n",
    "\n",
    "\n",
    "# Filter the \"revenue\" DataFrame for European countries\n",
    "revenue_europe = revenue[revenue['country_name'].isin(european_countries)]\n",
    "\n",
    "\n",
    "\n",
    "# Filter the \"debt\" DataFrame for European countries\n",
    "debt_europe = debt[debt['country_name'].isin(european_countries)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f0947b-4ca5-4bc0-b570-8375e02adfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expense_europe = expense_europe[expense_europe['attribute'] == 'Value']\n",
    "revenue_europe = revenue_europe[revenue_europe['attribute'] == 'Value']\n",
    "debt_europe = debt_europe[debt_europe['attribute'] == 'Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba966cc7-e570-4c51-b1d3-368508c61ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.628057228</td>\n",
       "      <td>2.611153533</td>\n",
       "      <td>2.5774434</td>\n",
       "      <td>1.596776593</td>\n",
       "      <td>1.52993013</td>\n",
       "      <td>1.513784968</td>\n",
       "      <td>1.605595415</td>\n",
       "      <td>1.666422717</td>\n",
       "      <td>2.681309827</td>\n",
       "      <td>2.108019478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Austria</td>\n",
       "      <td>0.61331997</td>\n",
       "      <td>0.588700326</td>\n",
       "      <td>0.581780822</td>\n",
       "      <td>0.728918317</td>\n",
       "      <td>1.056904473</td>\n",
       "      <td>1.208750988</td>\n",
       "      <td>1.495720728</td>\n",
       "      <td>1.5874903</td>\n",
       "      <td>1.689121558</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666046557</td>\n",
       "      <td>2.539129672</td>\n",
       "      <td>2.376957137</td>\n",
       "      <td>2.280235269</td>\n",
       "      <td>2.037720073</td>\n",
       "      <td>1.815921408</td>\n",
       "      <td>1.592841025</td>\n",
       "      <td>1.415853602</td>\n",
       "      <td>1.378380188</td>\n",
       "      <td>1.150676327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   country_name        1972         1973         1974         1975  \\\n",
       "0       Belgium         NaN          NaN          NaN          NaN   \n",
       "76      Austria  0.61331997  0.588700326  0.581780822  0.728918317   \n",
       "\n",
       "           1976         1977         1978       1979         1980  ...  \\\n",
       "0           NaN          NaN          NaN        NaN          NaN  ...   \n",
       "76  1.056904473  1.208750988  1.495720728  1.5874903  1.689121558  ...   \n",
       "\n",
       "           2012         2013         2014         2015         2016  \\\n",
       "0   2.628057228  2.611153533    2.5774434  1.596776593   1.52993013   \n",
       "76  2.666046557  2.539129672  2.376957137  2.280235269  2.037720073   \n",
       "\n",
       "           2017         2018         2019         2020         2021  \n",
       "0   1.513784968  1.605595415  1.666422717  2.681309827  2.108019478  \n",
       "76  1.815921408  1.592841025  1.415853602  1.378380188  1.150676327  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to drop (remove the outer list)\n",
    "expense_columns_to_drop = ['country_code', 'unit_name', 'unit_code', 'indicator_code', 'classification_name',\n",
    "                           'global_dsd_time_series_code', 'classification_code', 'sector_code', 'attribute', 'sector_name']\n",
    "\n",
    "# Use axis=1 to indicate that you want to drop columns\n",
    "expense_europe = expense_europe.drop(columns=expense_columns_to_drop)\n",
    "\n",
    "# Display the new DataFrame\n",
    "expense_europe.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e1e2a65-bd43-49bf-abbe-837d71537560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0419578532265966</td>\n",
       "      <td>0.04165352001882</td>\n",
       "      <td>0.0413812438446675</td>\n",
       "      <td>0.0408662637069294</td>\n",
       "      <td>0.0408687725106821</td>\n",
       "      <td>0.0398633534924294</td>\n",
       "      <td>0.0411417143565825</td>\n",
       "      <td>0.0373366271003739</td>\n",
       "      <td>0.0328429302284136</td>\n",
       "      <td>0.0304437715546219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name 1972 1973 1974 1975 1976 1977 1978 1979 1980  ...  \\\n",
       "0      Austria  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "6      Austria  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...   \n",
       "\n",
       "                 2012              2013                2014  \\\n",
       "0  0.0419578532265966  0.04165352001882  0.0413812438446675   \n",
       "6                 NaN               NaN                 NaN   \n",
       "\n",
       "                 2015                2016                2017  \\\n",
       "0  0.0408662637069294  0.0408687725106821  0.0398633534924294   \n",
       "6                 NaN                 NaN                 NaN   \n",
       "\n",
       "                 2018                2019                2020  \\\n",
       "0  0.0411417143565825  0.0373366271003739  0.0328429302284136   \n",
       "6                 NaN                 NaN                 NaN   \n",
       "\n",
       "                 2021  \n",
       "0  0.0304437715546219  \n",
       "6                 NaN  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to drop (remove the outer list)\n",
    "revenue_columns_to_drop = ['country_code', 'unit_name', 'unit_code', 'indicator_code', 'global_dsd_time_series_code',\n",
    "                           'classification_name', 'sector_name','classification_code', 'sector_code', 'unnamed:_61', 'attribute']\n",
    "\n",
    "# Use axis=1 to indicate that you want to drop columns\n",
    "revenue_europe =  revenue_europe.drop(columns=revenue_columns_to_drop)\n",
    "\n",
    "# Display the new DataFrame\n",
    "revenue_europe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b873f4-9c7b-4414-86d6-438d936d9217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "      <th>1803</th>\n",
       "      <th>1804</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>61.618800</td>\n",
       "      <td>68.439083</td>\n",
       "      <td>71.666333</td>\n",
       "      <td>83.609401</td>\n",
       "      <td>96.183319</td>\n",
       "      <td>111.389679</td>\n",
       "      <td>126.209890</td>\n",
       "      <td>129.000844</td>\n",
       "      <td>130.165395</td>\n",
       "      <td>128.976822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romania</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12.536329</td>\n",
       "      <td>12.651644</td>\n",
       "      <td>13.387073</td>\n",
       "      <td>23.347557</td>\n",
       "      <td>30.535338</td>\n",
       "      <td>33.874314</td>\n",
       "      <td>37.630485</td>\n",
       "      <td>38.826068</td>\n",
       "      <td>40.495409</td>\n",
       "      <td>39.304125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name  1800  1801  1802  1803  1804  1805  1806  1807  1808  ...  \\\n",
       "0     Portugal   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2      Romania   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "        2006       2007       2008       2009       2010        2011  \\\n",
       "0  61.618800  68.439083  71.666333  83.609401  96.183319  111.389679   \n",
       "2  12.536329  12.651644  13.387073  23.347557  30.535338   33.874314   \n",
       "\n",
       "         2012        2013        2014        2015  \n",
       "0  126.209890  129.000844  130.165395  128.976822  \n",
       "2   37.630485   38.826068   40.495409   39.304125  \n",
       "\n",
       "[2 rows x 217 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to drop (remove the outer list)\n",
    "debt_columns_to_drop = ['country_code', 'indicator_name', 'indicator_code', 'unnamed:_221', 'attribute']\n",
    "\n",
    "# Use axis=1 to indicate that you want to drop columns\n",
    "debt_europe = debt_europe.drop(columns= debt_columns_to_drop)\n",
    "\n",
    "# Display the new DataFrame\n",
    "debt_europe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78cb8d05-2a07-4be5-a840-ede96d0f6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns for the years 2000 to 2015\n",
    "selected_columns = ['country_name']+ [str(year) for year in range(2000, 2016)]\n",
    "\n",
    "# Select data only for the European Countries\n",
    "expense_europe = expense_europe[selected_columns]\n",
    "revenue_europe = revenue_europe[selected_columns]\n",
    "debt_europe = debt_europe[selected_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee03c960-8d23-4efc-8cd7-c98e5442a0f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace missing values with zero\n",
    "\n",
    "expense_column_range =expense_europe.columns[1:]  # Select columns from index 2 to the end\n",
    "expense_europe.loc[:, expense_column_range] =  expense_europe.loc[:, expense_column_range].fillna(0)\n",
    "\n",
    "revenue_column_range =revenue_europe.columns[1:]  # Select columns from index 2 to the end\n",
    "revenue_europe.loc[:, revenue_column_range] =  revenue_europe.loc[:, revenue_column_range].fillna(0)\n",
    "\n",
    "debt_column_range =debt_europe.columns[1:]  # Select columns from index 2 to the end\n",
    "debt_europe.loc[:, debt_column_range] =  debt_europe.loc[:, debt_column_range].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8afd3ee5-a866-49c3-ad10-39ad6f1ad4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>2000_exp</th>\n",
       "      <th>2001_exp</th>\n",
       "      <th>2002_exp</th>\n",
       "      <th>2003_exp</th>\n",
       "      <th>2004_exp</th>\n",
       "      <th>2005_exp</th>\n",
       "      <th>2006_exp</th>\n",
       "      <th>2007_exp</th>\n",
       "      <th>2008_exp</th>\n",
       "      <th>...</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>1.016085749</td>\n",
       "      <td>1.006374487</td>\n",
       "      <td>0.955115185</td>\n",
       "      <td>1.124213641</td>\n",
       "      <td>1.036217236</td>\n",
       "      <td>1.425862075</td>\n",
       "      <td>1.604331526</td>\n",
       "      <td>1.847220323</td>\n",
       "      <td>2.089315464</td>\n",
       "      <td>...</td>\n",
       "      <td>91.038109</td>\n",
       "      <td>87.021213</td>\n",
       "      <td>92.528538</td>\n",
       "      <td>99.563594</td>\n",
       "      <td>99.710354</td>\n",
       "      <td>102.336996</td>\n",
       "      <td>104.115402</td>\n",
       "      <td>105.186223</td>\n",
       "      <td>106.568051</td>\n",
       "      <td>106.052412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>1.016085749</td>\n",
       "      <td>1.006374487</td>\n",
       "      <td>0.955115185</td>\n",
       "      <td>1.124213641</td>\n",
       "      <td>1.036217236</td>\n",
       "      <td>1.425862075</td>\n",
       "      <td>1.604331526</td>\n",
       "      <td>1.847220323</td>\n",
       "      <td>2.089315464</td>\n",
       "      <td>...</td>\n",
       "      <td>91.038109</td>\n",
       "      <td>87.021213</td>\n",
       "      <td>92.528538</td>\n",
       "      <td>99.563594</td>\n",
       "      <td>99.710354</td>\n",
       "      <td>102.336996</td>\n",
       "      <td>104.115402</td>\n",
       "      <td>105.186223</td>\n",
       "      <td>106.568051</td>\n",
       "      <td>106.052412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_name     2000_exp     2001_exp     2002_exp     2003_exp  \\\n",
       "0      Belgium  1.016085749  1.006374487  0.955115185  1.124213641   \n",
       "1      Belgium  1.016085749  1.006374487  0.955115185  1.124213641   \n",
       "\n",
       "      2004_exp     2005_exp     2006_exp     2007_exp     2008_exp  ...  \\\n",
       "0  1.036217236  1.425862075  1.604331526  1.847220323  2.089315464  ...   \n",
       "1  1.036217236  1.425862075  1.604331526  1.847220323  2.089315464  ...   \n",
       "\n",
       "        2006       2007       2008       2009       2010        2011  \\\n",
       "0  91.038109  87.021213  92.528538  99.563594  99.710354  102.336996   \n",
       "1  91.038109  87.021213  92.528538  99.563594  99.710354  102.336996   \n",
       "\n",
       "         2012        2013        2014        2015  \n",
       "0  104.115402  105.186223  106.568051  106.052412  \n",
       "1  104.115402  105.186223  106.568051  106.052412  \n",
       "\n",
       "[2 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge expense and revenue on 'country_name'\n",
    "merged_df = pd.merge(expense_europe, revenue_europe, on='country_name', how='inner', suffixes=('_exp', '_rev'))\n",
    "\n",
    "# Merge the result with debt on 'country_name'\n",
    "merged_df = pd.merge(merged_df, debt_europe, on='country_name', how='inner')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "merged_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734ce561-1264-4c45-a615-488d261287ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert values in each year's column to numeric\n",
    "\n",
    "column_range =merged_df.columns[1:]  # Select columns from index 1 to the end\n",
    "\n",
    "merged_df[column_range] = merged_df[column_range].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976fb003-2a77-4af4-9f47-204199fcc411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "country_name    0\n",
      "2000_exp        0\n",
      "2001_exp        0\n",
      "2002_exp        0\n",
      "2003_exp        0\n",
      "2004_exp        0\n",
      "2005_exp        0\n",
      "2006_exp        0\n",
      "2007_exp        0\n",
      "2008_exp        0\n",
      "2009_exp        0\n",
      "2010_exp        0\n",
      "2011_exp        0\n",
      "2012_exp        0\n",
      "2013_exp        0\n",
      "2014_exp        0\n",
      "2015_exp        0\n",
      "2000_rev        0\n",
      "2001_rev        0\n",
      "2002_rev        0\n",
      "2003_rev        0\n",
      "2004_rev        0\n",
      "2005_rev        0\n",
      "2006_rev        0\n",
      "2007_rev        0\n",
      "2008_rev        0\n",
      "2009_rev        0\n",
      "2010_rev        0\n",
      "2011_rev        0\n",
      "2012_rev        0\n",
      "2013_rev        0\n",
      "2014_rev        0\n",
      "2015_rev        0\n",
      "2000            0\n",
      "2001            0\n",
      "2002            0\n",
      "2003            0\n",
      "2004            0\n",
      "2005            0\n",
      "2006            0\n",
      "2007            0\n",
      "2008            0\n",
      "2009            0\n",
      "2010            0\n",
      "2011            0\n",
      "2012            0\n",
      "2013            0\n",
      "2014            0\n",
      "2015            0\n",
      "dtype: int64\n",
      "The DataFrame does not have any missing values.\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the entire DataFrame\n",
    "missing_values = merged_df.isnull().sum()\n",
    "\n",
    "# Display the count of missing values for each column\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Check if there are any missing values in the entire DataFrame\n",
    "has_missing_values = merged_df.isnull().values.any()\n",
    "\n",
    "# Display the result\n",
    "if has_missing_values:\n",
    "    print(\"The DataFrame has missing values.\")\n",
    "else:\n",
    "    print(\"The DataFrame does not have any missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5016e552-a895-4c29-834e-d4701372c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract expense columns\n",
    "expense_columns = [col for col in merged_df.columns if col.endswith('_exp')]\n",
    "\n",
    "# Extract revenue columns\n",
    "revenue_columns = [col for col in merged_df.columns if col.endswith('_rev')]\n",
    "\n",
    "# Extract target columns (without suffix) for the selected years (2000 to 2015)\n",
    "target_columns = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "\n",
    "# Combine all columns into features list\n",
    "features = merged_df[expense_columns + revenue_columns]\n",
    "\n",
    "# target\n",
    "target = merged_df[target_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f89f162-1167-4420-999a-5461fada2427",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regressor Model Metrics:\n",
      "Mean Absolute Error: 23.780823293289227\n",
      "Mean Squared Error: 1003.4054105742175\n",
      "RMSE: 31.676575108022924\n",
      "R2: 0.045713192827855846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "\n",
    "print('Linear Regressor Model Metrics:')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0baf15-6eeb-45d1-bb37-a3d0edce8aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcba4031-4d14-420a-a95a-faf52b6596c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desicion Tree Regressor Model Metrics:\n",
      "Mean Absolute Error (MAE): 19.14\n",
      "Mean Squared Error (MSE): 776.00\n",
      "Root Mean Squared Error (RMSE): 27.79\n",
      "R-squared (R2): 0.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Regressor\n",
    "model2 = DecisionTreeRegressor(max_depth=10, random_state=42) # max_depth=10 to speed it up\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # RMSE\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Desicion Tree Regressor Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared (R2): {r2:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a755481c-3f36-4b34-b1aa-99ae5c996a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Model Metrics:\n",
      "Mean Absolute Error (MAE): 39.67\n",
      "Mean Squared Error (MSE): 2569.76\n",
      "Root Mean Squared Error (RMSE): 49.45\n",
      "R-squared (R2): -3.84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame\n",
    "\n",
    "# Extract expense columns\n",
    "expense_columns = [col for col in merged_df.columns if col.endswith('_exp')]\n",
    "\n",
    "# Extract revenue columns\n",
    "revenue_columns = [col for col in merged_df.columns if col.endswith('_rev')]\n",
    "\n",
    "# Extract target columns (without suffix) for the selected years (2000 to 2015)\n",
    "target_columns = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "\n",
    "# Combine expense and revenue columns into features list\n",
    "features_df = merged_df[['country_name'] + expense_columns + revenue_columns]\n",
    "\n",
    "# Melt the DataFrame to create a 'year' column\n",
    "features_melted = pd.melt(features_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted DataFrame to create a tabular structure\n",
    "features_tabular = features_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Extract target columns\n",
    "target_df = merged_df[['country_name'] + target_columns]\n",
    "\n",
    "# Melt the target DataFrame to create a 'year' column\n",
    "target_melted = pd.melt(target_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted target DataFrame to create a tabular structure\n",
    "target_tabular = target_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tabular.drop('country_name', axis=1), target_tabular.drop('country_name', axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree Regressor\n",
    "model_decision_tree = DecisionTreeRegressor(max_depth=10, random_state=42)  # Adjust hyperparameters if needed\n",
    "\n",
    "# Train the model\n",
    "model_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_decision_tree = model_decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_decision_tree = mean_absolute_error(y_test, y_pred_decision_tree)\n",
    "mse_decision_tree = mean_squared_error(y_test, y_pred_decision_tree)\n",
    "rmse_decision_tree = mean_squared_error(y_test, y_pred_decision_tree, squared=False)  # RMSE\n",
    "r2_decision_tree = r2_score(y_test, y_pred_decision_tree)\n",
    "\n",
    "# Print the evaluation metrics for the decision tree model\n",
    "print('Decision Tree Regressor Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_decision_tree:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_decision_tree:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_decision_tree:.2f}')\n",
    "print(f'R-squared (R2): {r2_decision_tree:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a6733-c75d-44c3-9088-3b4326322cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a Long time to run\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Define a smaller hyperparameter space\n",
    "param_dist = {\n",
    "    'max_depth': sp_randint(5, 21),\n",
    "    # Add more hyperparameters to tune if needed\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV instead of GridSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Adjust the number of iterations\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_random = random_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params_random}')\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model_random = random_search.best_estimator_\n",
    "y_pred_tuned_random = best_model_random.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "mae_tuned_random = mean_absolute_error(y_test, y_pred_tuned_random)\n",
    "mse_tuned_random = mean_squared_error(y_test, y_pred_tuned_random)\n",
    "rmse_tuned_random = mean_squared_error(y_test, y_pred_tuned_random, squared=False)  # RMSE\n",
    "r2_tuned_random = r2_score(y_test, y_pred_tuned_random)\n",
    "\n",
    "# Print the evaluation metrics for the tuned model\n",
    "print('\\nTuned Decision Tree Regressor Model Metrics (RandomizedSearchCV):')\n",
    "print(f'Mean Absolute Error (MAE): {mae_tuned_random:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_tuned_random:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_tuned_random:.2f}')\n",
    "print(f'R-squared (R2): {r2_tuned_random:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aafa89ae-c85a-4405-839e-18da34b456ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Metrics:\n",
      "Mean Absolute Error (MAE): 55.59\n",
      "Mean Squared Error (MSE): 4939.49\n",
      "Root Mean Squared Error (RMSE): 68.07\n",
      "R-squared (R2): -8.41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame\n",
    "\n",
    "# Extract expense columns\n",
    "expense_columns = [col for col in merged_df.columns if col.endswith('_exp')]\n",
    "\n",
    "# Extract revenue columns\n",
    "revenue_columns = [col for col in merged_df.columns if col.endswith('_rev')]\n",
    "\n",
    "# Extract target columns (without suffix) for the selected years (2000 to 2015)\n",
    "target_columns = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "\n",
    "# Combine expense and revenue columns into features list\n",
    "features_df = merged_df[['country_name'] + expense_columns + revenue_columns]\n",
    "\n",
    "# Melt the DataFrame to create a 'year' column\n",
    "features_melted = pd.melt(features_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted DataFrame to create a tabular structure\n",
    "features_tabular = features_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Extract target columns\n",
    "target_df = merged_df[['country_name'] + target_columns]\n",
    "\n",
    "# Melt the target DataFrame to create a 'year' column\n",
    "target_melted = pd.melt(target_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted target DataFrame to create a tabular structure\n",
    "target_tabular = target_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tabular.drop('country_name', axis=1), target_tabular.drop('country_name', axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model_linear = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_linear = model_linear.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_linear = mean_absolute_error(y_test, y_pred_linear)\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "rmse_linear = mean_squared_error(y_test, y_pred_linear, squared=False)  # RMSE\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "# Print the evaluation metrics for the linear regression model\n",
    "print('Linear Regression Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_linear:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_linear:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_linear:.2f}')\n",
    "print(f'R-squared (R2): {r2_linear:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b7ac781-226f-42c1-926a-3c58f52eda61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Model Metrics:\n",
      "Mean Absolute Error (MAE): 19.14\n",
      "Mean Squared Error (MSE): 766.24\n",
      "Root Mean Squared Error (RMSE): 27.61\n",
      "R-squared (R2): 0.27\n"
     ]
    }
   ],
   "source": [
    "# Took a long time to run\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Define X_train and y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "model_rf = RandomForestRegressor(max_depth=10, random_state=42)  # max_depth=10 to speed it up\n",
    "\n",
    "# Train the model\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)  # RMSE\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print the Random Forest Regressor model metrics\n",
    "print(\"Random Forest Regressor Model Metrics:\")\n",
    "print(f'Mean Absolute Error (MAE): {mae_rf:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_rf:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_rf:.2f}')\n",
    "print(f'R-squared (R2): {r2_rf:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1cf48b0-25f5-403c-8b49-f7e202572b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 50, 'max_depth': 30}\n",
      "\n",
      "Random Forest Regressor Model Metrics:\n",
      "Mean Absolute Error (MAE): 23.02\n",
      "Mean Squared Error (MSE): 884.29\n",
      "Root Mean Squared Error (RMSE): 29.58\n",
      "R-squared (R2): -0.70\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame\n",
    "\n",
    "# Extract expense columns\n",
    "expense_columns = [col for col in merged_df.columns if col.endswith('_exp')]\n",
    "\n",
    "# Extract revenue columns\n",
    "revenue_columns = [col for col in merged_df.columns if col.endswith('_rev')]\n",
    "\n",
    "# Extract target columns (without suffix) for the selected years (2000 to 2015)\n",
    "target_columns = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "\n",
    "# Combine expense and revenue columns into features list\n",
    "features_df = merged_df[['country_name'] + expense_columns + revenue_columns]\n",
    "\n",
    "# Melt the DataFrame to create a 'year' column\n",
    "features_melted = pd.melt(features_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted DataFrame to create a tabular structure\n",
    "features_tabular = features_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Extract target columns\n",
    "target_df = merged_df[['country_name'] + target_columns]\n",
    "\n",
    "# Melt the target DataFrame to create a 'year' column\n",
    "target_melted = pd.melt(target_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted target DataFrame to create a tabular structure\n",
    "target_tabular = target_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tabular.drop('country_name', axis=1), target_tabular.drop('country_name', axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150],  # Adjust the number of estimators\n",
    "    'max_depth': [None, 10, 20, 30],  # Adjust the maximum depth\n",
    "    # Add more hyperparameters to tune if needed\n",
    "}\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Adjust the number of iterations\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Use all available processors\n",
    ")\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_random = random_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params_random}')\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model_random = random_search.best_estimator_\n",
    "y_pred_random_forest = best_model_random.predict(X_test)\n",
    "\n",
    "# Evaluate the tuned model\n",
    "mae_random_forest = mean_absolute_error(y_test, y_pred_random_forest)\n",
    "mse_random_forest = mean_squared_error(y_test, y_pred_random_forest)\n",
    "rmse_random_forest = mean_squared_error(y_test, y_pred_random_forest, squared=False)  # RMSE\n",
    "r2_random_forest = r2_score(y_test, y_pred_random_forest)\n",
    "\n",
    "# Print the evaluation metrics for the tuned model\n",
    "print('\\nRandom Forest Regressor Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_random_forest:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_random_forest:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_random_forest:.2f}')\n",
    "print(f'R-squared (R2): {r2_random_forest:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ace7ada6-984f-4cc4-9c5f-fa0a491649b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Extended Grid): {'max_depth': 20, 'n_estimators': 100}\n",
      "\n",
      "Random Forest Regressor (Extended Grid) Model Metrics:\n",
      "Mean Absolute Error (MAE): 22.32\n",
      "Mean Squared Error (MSE): 810.17\n",
      "Root Mean Squared Error (RMSE): 28.29\n",
      "R-squared (R2): -0.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'merged_df' is your DataFrame\n",
    "\n",
    "# Extract expense columns\n",
    "expense_columns = [col for col in merged_df.columns if col.endswith('_exp')]\n",
    "\n",
    "# Extract revenue columns\n",
    "revenue_columns = [col for col in merged_df.columns if col.endswith('_rev')]\n",
    "\n",
    "# Extract target columns (without suffix) for the selected years (2000 to 2015)\n",
    "target_columns = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "\n",
    "# Combine expense and revenue columns into features list\n",
    "features_df = merged_df[['country_name'] + expense_columns + revenue_columns]\n",
    "\n",
    "# Melt the DataFrame to create a 'year' column\n",
    "features_melted = pd.melt(features_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted DataFrame to create a tabular structure\n",
    "features_tabular = features_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Extract target columns\n",
    "target_df = merged_df[['country_name'] + target_columns]\n",
    "\n",
    "# Melt the target DataFrame to create a 'year' column\n",
    "target_melted = pd.melt(target_df, id_vars=['country_name'], var_name='year', value_name='value')\n",
    "\n",
    "# Pivot the melted target DataFrame to create a tabular structure\n",
    "target_tabular = target_melted.pivot_table(index=['country_name'], columns='year', values='value').reset_index()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_tabular.drop('country_name', axis=1), target_tabular.drop('country_name', axis=1), test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (optional but can be beneficial)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check for missing values\n",
    "if np.isnan(X_train_scaled).sum().sum() > 0 or np.isnan(y_train.values).sum().sum() > 0:\n",
    "    raise ValueError(\"There are missing values in the data.\")\n",
    "\n",
    "# Ensure the shapes are consistent\n",
    "if X_train_scaled.shape[0] != y_train.shape[0]:\n",
    "    raise ValueError(\"Inconsistent number of samples between X_train_scaled and y_train.\")\n",
    "\n",
    "# Define an extended hyperparameter grid\n",
    "param_grid_extended = {\n",
    "    'n_estimators': [100, 150, 200],  # Try higher values\n",
    "    'max_depth': [20, 30, 40, None],  # Include higher values and None\n",
    "    # Add more hyperparameters to tune if needed\n",
    "}\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Instantiate GridSearchCV with the extended grid\n",
    "grid_search_extended = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid_extended,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the extended grid search to the data\n",
    "grid_search_extended.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the extended grid search\n",
    "best_params_extended = grid_search_extended.best_params_\n",
    "print(f'Best Hyperparameters (Extended Grid): {best_params_extended}')\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model_extended = grid_search_extended.best_estimator_\n",
    "y_pred_random_forest_extended = best_model_extended.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the extended grid search model\n",
    "mae_random_forest_extended = mean_absolute_error(y_test, y_pred_random_forest_extended)\n",
    "mse_random_forest_extended = mean_squared_error(y_test, y_pred_random_forest_extended)\n",
    "rmse_random_forest_extended = mean_squared_error(y_test, y_pred_random_forest_extended, squared=False)  # RMSE\n",
    "r2_random_forest_extended = r2_score(y_test, y_pred_random_forest_extended)\n",
    "\n",
    "# Print the evaluation metrics for the extended grid search model\n",
    "print('\\nRandom Forest Regressor (Extended Grid) Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_random_forest_extended:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_random_forest_extended:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_random_forest_extended:.2f}')\n",
    "print(f'R-squared (R2): {r2_random_forest_extended:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c67280fc-d22e-4b47-82d9-9c48c5ccbfd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Extended Grid): {'max_depth': 15, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "\n",
      "Random Forest Regressor (Extended Grid) Model Metrics:\n",
      "Mean Absolute Error (MAE): 23.72\n",
      "Mean Squared Error (MSE): 828.40\n",
      "Root Mean Squared Error (RMSE): 28.66\n",
      "R-squared (R2): -0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define an extended hyperparameter grid\n",
    "param_grid_extended = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [15, 20, 25, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    # Add more hyperparameters to tune if needed\n",
    "}\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Instantiate GridSearchCV with the extended grid\n",
    "grid_search_extended = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid_extended,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the extended grid search to the data\n",
    "grid_search_extended.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the extended grid search\n",
    "best_params_extended = grid_search_extended.best_params_\n",
    "print(f'Best Hyperparameters (Extended Grid): {best_params_extended}')\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model_extended = grid_search_extended.best_estimator_\n",
    "y_pred_random_forest_extended = best_model_extended.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the extended grid search model\n",
    "mae_random_forest_extended = mean_absolute_error(y_test, y_pred_random_forest_extended)\n",
    "mse_random_forest_extended = mean_squared_error(y_test, y_pred_random_forest_extended)\n",
    "rmse_random_forest_extended = mean_squared_error(y_test, y_pred_random_forest_extended, squared=False)  # RMSE\n",
    "r2_random_forest_extended = r2_score(y_test, y_pred_random_forest_extended)\n",
    "\n",
    "# Print the evaluation metrics for the extended grid search model\n",
    "print('\\nRandom Forest Regressor (Extended Grid) Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_random_forest_extended:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_random_forest_extended:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_random_forest_extended:.2f}')\n",
    "print(f'R-squared (R2): {r2_random_forest_extended:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df211c-25a0-4f6a-af73-0d904df5e93f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract expense columns\n",
    "expense_columns = [col for col in merged_df.columns if col.endswith('_exp')]\n",
    "\n",
    "# Extract revenue columns\n",
    "revenue_columns = [col for col in merged_df.columns if col.endswith('_rev')]\n",
    "\n",
    "# Extract target columns (without suffix) for the selected years (2000 to 2015)\n",
    "target_columns = ['2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "\n",
    "# Combine all columns into features list\n",
    "features = merged_df[expense_columns + revenue_columns]\n",
    "\n",
    "# Summing debt values across all years\n",
    "target = merged_df[target_columns].sum(axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define an extended hyperparameter grid for Random Forest Regressor\n",
    "param_grid_extended = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [15, 20, 25],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    # Add more hyperparameters to tune if needed\n",
    "}\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Instantiate GridSearchCV with the extended grid\n",
    "grid_search_extended = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid_extended,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# Fit the extended grid search to the data\n",
    "grid_search_extended.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the extended grid search\n",
    "best_params_extended = grid_search_extended.best_params_\n",
    "print(f'Best Hyperparameters (Extended Grid): {best_params_extended}')\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model_extended = grid_search_extended.best_estimator_\n",
    "y_pred_random_forest_extended = best_model_extended.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the extended grid search model\n",
    "mae_random_forest_extended = mean_absolute_error(y_test, y_pred_random_forest_extended)\n",
    "mse_random_forest_extended = mean_squared_error(y_test, y_pred_random_forest_extended)\n",
    "rmse_random_forest_extended = mean_squared_error(y_test, y_pred_random_forest_extended, squared=False)  # RMSE\n",
    "r2_random_forest_extended = r2_score(y_test, y_pred_random_forest_extended)\n",
    "\n",
    "# Print the evaluation metrics for the extended grid search model\n",
    "print('\\nRandom Forest Regressor (Extended Grid) Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_random_forest_extended:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_random_forest_extended:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_random_forest_extended:.2f}')\n",
    "print(f'R-squared (R2): {r2_random_forest_extended:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8066e6-5698-4c3c-b15a-f6d9340a569c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define hyperparameter grid for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Create Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Perform randomized search for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=10, cv=5, random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Train Random Forest Regressor with the best hyperparameters\n",
    "model_rf_best = RandomForestRegressor(**best_params, random_state=42)\n",
    "model_rf_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf_best = model_rf_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_rf_best = mean_absolute_error(y_test, y_pred_rf_best)\n",
    "mse_rf_best = mean_squared_error(y_test, y_pred_rf_best)\n",
    "rmse_rf_best = mean_squared_error(y_test, y_pred_rf_best, squared=False)  # RMSE\n",
    "r2_rf_best = r2_score(y_test, y_pred_rf_best)\n",
    "\n",
    "# Print the evaluation metrics for Random Forest with feature scaling and hyperparameter tuning\n",
    "print('Random Forest Regressor Model Metrics (with Feature Scaling and Hyperparameter Tuning):')\n",
    "print(f'Mean Absolute Error (MAE): {mae_rf_best:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_rf_best:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_rf_best:.2f}')\n",
    "print(f'R-squared (R2): {r2_rf_best:.2f}')\n",
    "print('Best Hyperparameters:', best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912a421-85e9-4db7-a6a8-e2d343844e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b6103-4947-4c39-bca6-fdee07c5e95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91a90c-586c-41c6-b913-a64f63d5c8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Reduce the number of estimators (trees) to speed up training\n",
    "model_gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# target is a DataFrame with shape (2533256, 16), selecting a specific column from your multi-output target variable to get 1D array\n",
    "y_train_single_column = y_train.iloc[:, 0]\n",
    "\n",
    "# Create and train the Gradient Boosting Regressor\n",
    "model_gbr.fit(X_train, y_train_single_column)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_gbr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test.iloc[:, 0], y_pred)\n",
    "mse = mean_squared_error(y_test.iloc[:, 0], y_pred)\n",
    "rmse = mean_squared_error(y_test.iloc[:, 0], y_pred, squared=False)  # RMSE\n",
    "r2 = r2_score(y_test.iloc[:, 0], y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Gradient Boosting Regressor Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
    "print(f'R-squared (R2): {r2:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f9a13-ba54-4e13-acf1-3056458eb8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Lasso regression model\n",
    "model_lasso = Lasso(alpha=1.0, random_state=42)  # You can adjust the regularization strength (alpha) as needed\n",
    "model_lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "rmse_lasso = mean_squared_error(y_test, y_pred_lasso, squared=False)  # RMSE\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Print the evaluation metrics for Lasso regression\n",
    "print('Lasso Regression Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_lasso:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_lasso:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_lasso:.2f}')\n",
    "print(f'R-squared (R2): {r2_lasso:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b363f8-ef17-4495-84a9-c73fbc390f50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# target is a DataFrame with shape (2533256, 16), selecting a specific column from your multi-output target variable to get 1D array\n",
    "y_train_single_column = y_train.iloc[:, 0]\n",
    "\n",
    "# Create and train the Lasso regression model\n",
    "model_lasso = Lasso(alpha=1.0, random_state=42)  # You can adjust the regularization strength (alpha) as needed\n",
    "model_lasso.fit(X_train, y_train_single_column)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_lasso = mean_absolute_error(y_test.iloc[:, 0], y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test.iloc[:, 0], y_pred_lasso)\n",
    "rmse_lasso = mean_squared_error(y_test.iloc[:, 0], y_pred_lasso, squared=False)  # RMSE\n",
    "r2_lasso = r2_score(y_test.iloc[:, 0], y_pred_lasso)\n",
    "\n",
    "# Print the evaluation metrics for Lasso regression\n",
    "print('Lasso Regression Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_lasso:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_lasso:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_lasso:.2f}')\n",
    "print(f'R-squared (R2): {r2_lasso:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeac8ee-96f9-4095-b2e3-d2fa8747e2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d6975-0562-402f-b378-e07a4b781776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8784f-5060-49e0-9e10-36df1f6b50fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aca9099-2f78-4b17-b8a1-8d5b9f2fdef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the Ridge regression model\n",
    "model_ridge = Ridge(alpha=1.0)  # You can adjust the regularization strength (alpha) as needed\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = mean_squared_error(y_test, y_pred_ridge, squared=False)  # RMSE\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "# Print the evaluation metrics for Ridge regression\n",
    "print('Ridge Regression Model Metrics:')\n",
    "print(f'Mean Absolute Error (MAE): {mae_ridge:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_ridge:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_ridge:.2f}')\n",
    "print(f'R-squared (R2): {r2_ridge:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869b79a-6a1f-4fbf-9610-c04607da7d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define a range of alpha values for hyperparameter tuning\n",
    "alphas = [0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "# Create Ridge Regression model\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Perform grid search for hyperparameter tuning\n",
    "param_grid = {'alpha': alphas}\n",
    "grid_search = GridSearchCV(ridge_model, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# Train Ridge Regression with the best alpha\n",
    "model_ridge_best = Ridge(alpha=best_alpha)\n",
    "model_ridge_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_ridge_best = model_ridge_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_ridge_best = mean_absolute_error(y_test, y_pred_ridge_best)\n",
    "mse_ridge_best = mean_squared_error(y_test, y_pred_ridge_best)\n",
    "rmse_ridge_best = mean_squared_error(y_test, y_pred_ridge_best, squared=False)  # RMSE\n",
    "r2_ridge_best = r2_score(y_test, y_pred_ridge_best)\n",
    "\n",
    "# Print the evaluation metrics for Ridge regression with feature scaling and hyperparameter tuning\n",
    "print('Ridge Regression Model Metrics (with Feature Scaling and Hyperparameter Tuning):')\n",
    "print(f'Mean Absolute Error (MAE): {mae_ridge_best:.2f}')\n",
    "print(f'Mean Squared Error (MSE): {mse_ridge_best:.2f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse_ridge_best:.2f}')\n",
    "print(f'R-squared (R2): {r2_ridge_best:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de70f41-009d-420d-b652-18aaeb765f37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
